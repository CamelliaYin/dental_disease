{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97e95df8-f52b-4916-962f-1dbee57e6dab",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "This notebook contains all the experiments conducted for the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7163d8c9-08fd-40ab-8e3e-793982519701",
   "metadata": {},
   "source": [
    "## Experiment Set 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f0beb8-b7aa-47f1-b244-8a7fb4b3b3e4",
   "metadata": {},
   "source": [
    "### This experiment set is to test the results using the smaller test dataset of 5 annotators (including 1 expert). Results are reproduced from the development of the crowd yolo model, compared to other models using the same dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8253cc6-77ab-4c1c-9819-679b473f5f36",
   "metadata": {},
   "source": [
    "The dataset used is a small dataset of 100 radiographs with 5 annotators (500 sets of labels) one of which is compleeted by a dental expert. The expert labels are separated and used as ground truth labels for the test dataset.\n",
    "\n",
    "\n",
    "There are 4 models/techniques to expeiment:\n",
    "- `Crowd Yolo`: A combination of YoloV5 object detection algorithm and a bayesian classifier combination network BCCNet (a network that decides the annotators value as an annotator inorder to train the yolo model). (main model the paper is about)\n",
    "- `Crowd RCNN`: Another crowdsourced object detection model using an RCNN object detection model and a bayesian classifier combination network BCCNet (This main model we are comparing the results to)\n",
    "- `YoloV5 IID`: This model doesn't have crowdsourcing functionality and is just YoloV5 object detection. The data to train this model has to be treated as ground truth data, so a separate dataset is used where different annotators for a single image are separated and treated as individual ground truth labels..\n",
    "- `YoloV5 Agregation Preprocessing`: This algorithm agregates nearby labels of the same disease to create ground truth labels from crowdsourced labels (Not Machine learning). It will also use yoloV5 for the object detection `MIGHT NOT BE NEEDED`\n",
    "\n",
    "\n",
    "`ALL MODELS HAVE HYPERPAMETER TUNING AND ARE TRAINED TO THE BEST OF OUR ABILITY`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f47de0-ab8b-4c58-b113-956638f4eb9e",
   "metadata": {},
   "source": [
    "|  | `Dataset 1 (All Annotators) [CSall]` | `Test Data (Ground Truth) [GTtest]` |\n",
    "|---|---|---|\n",
    "| `Crowd Yolo` | Expert and non-expert Crowdsourced data | `Expert ground truth unseen data. Used as the test dataset for both train datasets.` |\n",
    "| `Crowd  RCNN` | Expert and non-expert Crowdsourced data | `Expert ground truth unseen data. Used as the test dataset for both train datasets.` |\n",
    "| `YoloV5 IID` | Images are repeated and labels are separated to act as ground trouth labels for each radiograph (from same dataset) | `Expert ground truth unseen data. Used as the test dataset for both train datasets.` |\n",
    "| `MIGHT NOT BE NEEDED` `YoloV5 Agregation Preprocessing` | Expert and non-expert Crowdsourced data agregated into ground truth labels | `Expert ground truth unseen data. Used as the test dataset for both train datasets.` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c315ee6b-3bf7-490c-9d27-5f59280518f9",
   "metadata": {},
   "source": [
    "## Experiment Set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becaeccc-cdee-4fa8-8aed-1ebdc7cb72e3",
   "metadata": {},
   "source": [
    "There are 3 datasets used in these experiments:\n",
    "- `Dataset 1 (CSall)`: Crowdsourced with both expert and non-expert labels \n",
    "- `Dataset 2 (CSexp)`: Crowdsourced (same dataset as above) with just expert labels filtered, no non-expert labels.  \n",
    "- `Test Dataset (GTtest)`: Expert only ground truth labels with unseen data (small dataset completed by a single expert)\n",
    "\n",
    "There are 4 models/techniques to expeiment:\n",
    "- `Crowd Yolo`: A combination of YoloV5 object detection algorithm and a bayesian classifier combination network BCCNet (a network that decides the annotators value as an annotator inorder to train the yolo model). (main model the paper is about)\n",
    "- `Crowd RCNN`: Another crowdsourced object detection model using an RCNN object detection model and a bayesian classifier combination network BCCNet (This main model we are comparing the results to)\n",
    "- `YoloV5 IID`: This model doesn't have crowdsourcing functionality and is just YoloV5 object detection. The data to train this model has to be treated as ground truth data, so a separate dataset is used where different annotators for a single image are separated and treated as individual ground truth labels..\n",
    "- `YoloV5 Agregation Preprocessing`: This algorithm agregates nearby labels of the same disease to create ground truth labels from crowdsourced labels (Not Machine learning). It will also use yoloV5 for the object detection `MIGHT NOT BE NEEDED`\n",
    "\n",
    "\n",
    "`ALL MODELS HAVE HYPERPAMETER TUNING AND ARE TRAINED TO THE BEST OF OUR ABILITY`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd9a1f8-2c21-4857-bdd3-240e4da9d9fa",
   "metadata": {},
   "source": [
    "|  | `Dataset 1 (All Annotators) [CSall]` | `Dataset 2 (Expert Labels Only) [CSexp]` | `Test Data (Ground Truth) [GTtest]` |\n",
    "|---|---|---|---|\n",
    "| `Crowd Yolo` | Expert and non-expert Crowdsourced data | Expert Crowdsourced data | `Expert ground truth unseen data. Used as the test dataset for both train datasets.` |\n",
    "| `Crowd  RCNN` | Expert and non-expert Crowdsourced data | Expert Crowdsourced data | `Expert ground truth unseen data. Used as the test dataset for both train datasets.` |\n",
    "| `YoloV5 IID` | Images are repeated and labels are separated to act as ground trouth labels for each radiograph (from same dataset) | Images are repeated and labels are separated to act as ground trouth labels only for expert annotator labels for each radiograph (from same dataset) | `Expert ground truth unseen data. Used as the test dataset for both train datasets.` |\n",
    "| `MIGHT NOT BE NEEDED` `YoloV5 Agregation Preprocessing` | Expert and non-expert Crowdsourced data agregated into ground truth labels | Expert only Crowdsourced data agregated into ground truth labels | `Expert ground truth unseen data. Used as the test dataset for both train datasets.` |\n",
    "\n",
    "LAST ONE MIGHT NOT BE NEEDED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e229c0ec-b3ea-4422-ba99-5e573f862ce9",
   "metadata": {},
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d55803f-149f-4020-bbfc-980fe8391013",
   "metadata": {},
   "source": [
    "#### Please run the 'Install Requirements.ipynb' file in the base folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8d0d3c-99d7-41d7-b01f-4dce875167f3",
   "metadata": {},
   "source": [
    "## Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ec26ee-2784-48aa-9f7e-b82d1b047192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as mpatch\n",
    "import matplotlib\n",
    "sys.path.append('../src/cyolo_utils')\n",
    "from results_plotter import read_exp_results as read_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6327df03-53ab-474d-8917-152300d2ede7",
   "metadata": {},
   "source": [
    "### Choice of Hyper Parameters\n",
    "\n",
    "Below are all the inital parameters you can change.\n",
    "\n",
    "\n",
    "\n",
    "| `Parameter` | `Description` | `Type` | `Default` |\n",
    "| --- | --- | --- | --- |\n",
    "| bcc_epoch | start-epoch for BCC+YOLO run; use -1 for no BCC. | int | 0 |\n",
    "| qtfilter_epoch | start-epoch for qt-filter; use -1 for no qt-filter. | int | -1 |\n",
    "| qt_thres_mode | one of '', 'conf-count', 'entropy', 'conf-val' | str | '' |\n",
    "| qt_thres | the threshold value. | float | 0.0 |\n",
    "| hybrid_entropy_thres | the entropy threshold value (only to be used when running the hybrid filter). | float | 0.0 |\n",
    "| hybrid_conf_thres | the confidence threshold value (only to be used when running the hybrid filter). | float | 0.0 |\n",
    "| weights | initial weights path | str | 'yolov5s.pt' |\n",
    "| cfg | model.yaml path | str | '' |\n",
    "| data | dataset.yaml path | str | '../data/coco128.yaml' |\n",
    "| hyp | hyperparameters path | str | '../data/hyps/hyp.scratch.yaml' |\n",
    "| epochs | number of epoch repeates | int | 300 |\n",
    "| batch-size | total batch size for all GPUs | int | 16 |\n",
    "| imgsz | train, val image size (pixels) | int | 640 |\n",
    "| rect | rectangular training | call | store_true |\n",
    "| resume | resume most recent training | bool | False |\n",
    "| nosave | only save final checkpoint | call | store_true |\n",
    "| noval | only validate final epoch | call | store_true |\n",
    "| noautoanchor | disable autoanchor check | call | store_true |\n",
    "| evolve | evolve hyperparameters for x generations | int | const:300 |\n",
    "| bucket | gsutil bucket | str | '' |\n",
    "| cache | --cache images in \"ram\" (default) or \"disk\" | str | const:'ram' |\n",
    "| image-weights | use weighted image selection for training | call | store_true |\n",
    "| device | cuda device, i.e. 0 or 0,1,2,3 or cpu | call | store_true |\n",
    "| multi-scale | vary img-size +/- 50%% | call | store_true |\n",
    "| single-cls | train multi-class data as single-class | call | store_true |\n",
    "| adam | use torch.optim.Adam() optimizer | call | store_true |\n",
    "| sync-bn | use SyncBatchNorm, only available in DDP mode | call | store_true |\n",
    "| workers | maximum number of dataloader workers | int | 8 |\n",
    "| project | save to project/name | N/A | runs/train |\n",
    "| entity | W&B entity | N/A | None |\n",
    "| name | save to project/name | N/A | 'exp' |\n",
    "| exist-ok | existing project/name ok, do not increment | call | store_true |\n",
    "| quad | quad dataloader | call | store_true |\n",
    "| linear-lr | linear LR | call | store_true |\n",
    "| label-smoothing | Label smoothing epsilon | float | 0.0 |\n",
    "| upload_dataset | Upload dataset as W&B artifact table | call | store_true |\n",
    "| bbox_interval | Set bounding-box image logging interval for W&B | int | -1 |\n",
    "| save_period | Log model after every \"save_period\" epoch | int | -1 |\n",
    "| artifact_alias | version of dataset artifact to be used | str | latest |\n",
    "| local_rank | DDP parameter, do not modify | int | -1 |\n",
    "| freeze | Number of layers to freeze. backbone=10, all=24 | int | 0 |\n",
    "| patience | EarlyStopping patience (epochs) | int | 1100 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc76c8e-42ee-402d-9901-c962561abe71",
   "metadata": {},
   "source": [
    "# EXPERIMENT SET 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b8126-83e2-438c-b55a-7a03fb726833",
   "metadata": {},
   "source": [
    "# Experiment 1 (Crowd Yolo Model)\n",
    "\n",
    "### This section runs the experiments, prints results, and plots graphs for both dataset using the Crowd Yolo model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2589751-3be2-4296-a10a-1b66317e9205",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r yolov5_master/requirements.txt\n",
    "!pip install python-utils\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a677a9e-ae95-46d3-b5d7-509b4401342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "#!pip install seaborn\n",
    "#!pip install torch\n",
    "#!pip3 install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html --user\n",
    "#!wandb login --host=https://api.wandb.ai\n",
    "#!wandb login --relogin b0d31701f11706105f7eec6a2d5cff4f9e89b18c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa3a071-beb1-419b-b152-4d7615b9ebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "%run -i ../src/train.py --data ../data/All_Volunteers_Calc_Removed_100min_test_Crowdsourced.yaml --batch-size 20 --epochs 25 --bcc_epoch 0 --name testtestLARGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d0b48a-e7f8-4dd3-a65f-7cfcdd58b256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-2-8 torch 1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 3090, 24575.5MB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, obj=1.0, cls=0.5, cls_pw=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mbcc_epoch=0, confusion_matrix_diagonal_prior_hyp=0.1, convergence_threshold_hyp=1e-06, qtfilter_epoch=-1, qt_thres_mode=, qt_thres=0.0, hybrid_entropy_thres=0.0, hybrid_conf_thres=0.0, weights=yolov5s.pt, cfg=, data=../data/All_Volunteers_Calc_Removed_Crowdsourced.yaml, hyp=../data/hyps/hyp.scratch.yaml, epochs=25, batch_size=20, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=testtestLARGE, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=1100\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "device:  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdddetection\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/dddetection/YOLOv5/runs/3qcor8jl\" target=\"_blank\">testtestLARGE</a></strong> to <a href=\"https://wandb.ai/dddetection/YOLOv5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "C:\\Users\\rb01243\\Anaconda3\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 270 layers, 7025023 parameters, 7025023 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 344/350 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00046875\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation is:  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '..\\data\\datasets\\All_Volunteers_Calc_Removed_Crowdsourced\\labels\\train.cache' images and labels... 1552 found, 0 missing, 0 empty, 1 corrupted: 100%|██████████| 1552/1552 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label ..\\data\\datasets\\All_Volunteers_Calc_Removed_Crowdsourced\\images\\train\\Unknown-X-20200130-084742-XLGSYPPPTEXC-0.JPG: non-normalized or out of bounds coordinate labels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\data\\datasets\\All_Volunteers_Calc_Removed_Crowdsourced\\labels\\val.cache' images and labels... 388 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 388/388 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\testtestLARGE4\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.37, Best Possible Recall (BPR) = 0.9985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/24     7.13G         0   0.01126         0       151       640: 100%|██████████| 78/78 [04:14<00:00,  3.26s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 10/10 [00:02<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        388       4923    0.00695       0.03    0.00271    0.00057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 78/78 [00:12<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1551      17030    0.00526     0.0411    0.00249   0.000511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      1/24     8.92G         0  0.003643         0       151       640: 100%|██████████| 78/78 [04:14<00:00,  3.26s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 10/10 [00:03<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        388       4923    0.00644     0.0362    0.00276   0.000575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 78/78 [00:09<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1551      17030    0.00603     0.0452    0.00251   0.000504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      2/24     8.93G         0   0.00188         0       151       640: 100%|██████████| 78/78 [04:11<00:00,  3.22s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 10/10 [00:02<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        388       4923    0.00565     0.0608    0.00312   0.000664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 78/78 [00:09<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1551      17030    0.00548     0.0719    0.00307   0.000649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      3/24     12.2G         0  0.001387         0       226       640:  19%|█▉        | 15/78 [00:48<03:21,  3.19s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "%run -i ../src/train.py --data ../data/All_Volunteers_Calc_Removed_Crowdsourced.yaml --batch-size 20 --epochs 25 --bcc_epoch 0 --name testtestLARGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48630b23-4e52-42f2-b63e-0e29546493c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-2-8 torch 1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 3090, 24575.5MB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, obj=1.0, cls=0.5, cls_pw=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mbcc_epoch=0, confusion_matrix_diagonal_prior_hyp=0.1, convergence_threshold_hyp=1e-06, qtfilter_epoch=-1, qt_thres_mode=, qt_thres=0.0, hybrid_entropy_thres=0.0, hybrid_conf_thres=0.0, weights=yolov5s.pt, cfg=, data=../data/cyolo.yaml, hyp=../data/hyps/hyp.scratch.yaml, epochs=25, batch_size=20, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=testtest, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=1100\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "device:  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdddetection\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/dddetection/YOLOv5/runs/1e0ts3pl\" target=\"_blank\">testtest</a></strong> to <a href=\"https://wandb.ai/dddetection/YOLOv5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "C:\\Users\\rb01243\\Anaconda3\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 270 layers, 7025023 parameters, 7025023 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 344/350 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00046875\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation is:  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '..\\data\\datasets\\bcc-tvt\\labels\\train.cache' images and labels... 70 found, 0 missing, 3 empty, 0 corrupted: 100%|██████████| 70/70 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\data\\datasets\\iid-tvt\\labels\\val.cache' images and labels... 67 found, 13 missing, 0 empty, 0 corrupted: 100%|██████████| 80/80 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\testtest2\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 6.02, Best Possible Recall (BPR) = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/24     6.66G   0.09169   0.04994   0.02048       124       640: 100%|██████████| 4/4 [00:05<00:00,  1.38s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:01<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220    0.00126     0.0232   0.000377   7.38e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:01<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961    0.00281     0.0152    0.00132   0.000272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      1/24     8.17G    0.1201   0.08077   0.02779       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.53it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220    0.00109    0.00258   0.000282   7.78e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:01<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961    0.00286       0.02    0.00125   0.000293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      2/24     8.16G     0.116    0.0896   0.02777       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.33it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:01<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220   0.000858     0.0502   0.000366   8.24e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:01<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961    0.00278     0.0235    0.00121   0.000292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      3/24     8.17G    0.1103    0.1032   0.02764       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.48it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0176     0.0192     0.0011   0.000155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:01<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961    0.00285     0.0484    0.00151   0.000407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      4/24     8.16G    0.1043    0.1169   0.02755       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.50it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:01<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0122     0.0192   0.000883   0.000202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:01<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961    0.00316     0.0418    0.00166   0.000403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      5/24     8.16G   0.09915    0.1292   0.02746       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.51it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220   0.000714     0.0656   0.000392   0.000112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:01<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961    0.00348     0.0589    0.00187   0.000344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      6/24     8.16G   0.09533    0.1379    0.0274       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.46it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:01<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0012     0.0309   0.000614   0.000134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:01<00:00,  2.44it/s]\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961    0.00302     0.0476    0.00171   0.000343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "YOLO+BCC\n",
      "      7/24     8.16G   0.09294    0.1438   0.02737       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.53it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220    0.00169     0.0335   0.000889   0.000173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:01<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961    0.00418     0.0388    0.00467   0.000693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      8/24     8.17G   0.09096    0.1482   0.02734       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.50it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0124     0.0284    0.00217   0.000475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:02<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961     0.0169     0.0177    0.00621    0.00126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      9/24     8.17G   0.08943      0.15   0.02728       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.47it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0345     0.0335    0.00521    0.00122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:02<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961     0.0238     0.0326     0.0093    0.00197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     10/24     8.18G    0.0882     0.149   0.02718       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.45it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0522     0.0464     0.0126    0.00258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961     0.0434     0.0519     0.0177    0.00331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     11/24     8.17G   0.08721    0.1469   0.02716       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.38it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0638     0.0541     0.0177    0.00312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:03<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961     0.0703      0.075     0.0288    0.00551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     12/24     8.18G   0.08688    0.1432   0.02716       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.56it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0338     0.0593    0.00967    0.00173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961     0.0761     0.0708     0.0228    0.00447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     13/24     8.16G   0.08566    0.1417   0.02712       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.51it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:04<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0739     0.0412     0.0265    0.00416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:03<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961     0.0935      0.102     0.0443    0.00864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     14/24     8.17G   0.08473    0.1402   0.02698       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.52it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0309      0.169     0.0215    0.00394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:02<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961     0.0917      0.137     0.0497     0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     15/24     8.18G   0.08398    0.1376   0.02682       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.52it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0456     0.0799     0.0268    0.00493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961      0.109      0.116     0.0526    0.00962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     16/24     8.17G   0.08331    0.1354   0.02654       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.43it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0488     0.0928     0.0252    0.00428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:02<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961      0.103      0.132     0.0519    0.00954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     17/24     8.18G   0.08242    0.1336   0.02625       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.48it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220      0.043      0.113     0.0231    0.00409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:02<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961     0.0982      0.152     0.0565    0.00998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     18/24     8.17G   0.08168    0.1313   0.02588       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.42it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0575     0.0797     0.0273    0.00441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:02<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961      0.106      0.124     0.0568    0.00961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     19/24     8.18G   0.08076    0.1296   0.02537       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.48it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0655     0.0825     0.0305    0.00503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:02<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961     0.0985      0.141     0.0577       0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     20/24     8.17G   0.07963     0.128   0.02467       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.35it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0537      0.119     0.0333    0.00515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:02<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961      0.116      0.127     0.0628     0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     21/24     8.18G   0.07852    0.1266   0.02386       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.47it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0616      0.101     0.0332    0.00514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:02<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961      0.116      0.125     0.0659     0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     22/24     8.17G   0.07757     0.125   0.02293       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.33it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220      0.051      0.116     0.0267    0.00454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:02<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961      0.116      0.143     0.0706     0.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     23/24     8.18G   0.07648    0.1234   0.02174       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.15it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0502      0.106     0.0274    0.00452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:01<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961      0.113      0.148     0.0718     0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     24/24     8.18G   0.07579    0.1223   0.02096       124       640: 100%|██████████| 4/4 [00:01<00:00,  2.36it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:05<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0546      0.108     0.0276    0.00446\n",
      "           bone-loss         80        194      0.109      0.216      0.055    0.00883\n",
      "       dental-caries         80         26          0          0   0.000325   8.72e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 4/4 [00:08<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         70        961      0.112      0.167     0.0776      0.013\n",
      "           bone-loss         70        858      0.221      0.325      0.154     0.0259\n",
      "       dental-caries         70        103    0.00315    0.00971    0.00129   0.000175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25 epochs completed in 0.056 hours.\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0566      0.111     0.0287     0.0046\n",
      "\n",
      "Evaluating pycocotools mAP... saving runs\\train\\testtest2\\_predictions.json...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m pycocotools not found and is required by YOLOv5, attempting auto-update...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Command 'pip install 'pycocotools'' returned non-zero exit status 1.\n",
      "pycocotools unable to run: No module named 'pycocotools'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220     0.0568      0.116     0.0335    0.00506\n",
      "\n",
      "Evaluating pycocotools mAP... saving runs\\train\\testtest2\\_predictions.json...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m pycocotools not found and is required by YOLOv5, attempting auto-update...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Command 'pip install 'pycocotools'' returned non-zero exit status 1.\n",
      "pycocotools unable to run: No module named 'pycocotools'\n",
      "Optimizer stripped from runs\\train\\testtest2\\weights\\last.pt, 14.3MB\n",
      "Optimizer stripped from runs\\train\\testtest2\\weights\\best.pt, 14.3MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10176... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 68.96MB of 69.39MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.993802525…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>metrics/mAP_0.5</td><td>▁▁▁▁▁▁▁▁▁▂▄▅▃▇▅▇▆▆▇▇██▇▇▇</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>▁▁▁▁▁▁▁▁▂▃▄▅▃▇▆█▇▇▇███▇▇▇</td></tr><tr><td>metrics/precision</td><td>▁▁▁▃▂▁▁▁▂▄▆▇▄█▄▅▆▅▆▇▆▇▆▆▆</td></tr><tr><td>metrics/recall</td><td>▂▁▃▂▂▄▂▂▂▂▃▃▃▃█▄▅▆▄▄▆▅▆▅▅</td></tr><tr><td>train/box_loss</td><td>▄█▇▆▆▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/cls_loss</td><td>▁█████████▇▇▇▇▇▇▇▇▆▆▅▄▃▂▁</td></tr><tr><td>train/obj_loss</td><td>▁▃▄▅▆▇▇██████▇▇▇▇▇▇▇▆▆▆▆▆</td></tr><tr><td>val/box_loss</td><td>█▇▆▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val/cls_loss</td><td>██▇▇▆▆▆▆▆▆▆▆▆▆▆▅▅▅▄▄▃▃▂▂▁</td></tr><tr><td>val/obj_loss</td><td>▁▁▁▂▂▂▂▂▂▃▄▅▃▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>x/lr0</td><td>▁▂▃▄▅▅▆▇▇███████▇▇▇▆▆▆▅▅▅</td></tr><tr><td>x/lr1</td><td>▁▂▃▄▅▅▆▇▇███████▇▇▇▆▆▆▅▅▅</td></tr><tr><td>x/lr2</td><td>██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>metrics/mAP_0.5</td><td>0.02765</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>0.00446</td></tr><tr><td>metrics/precision</td><td>0.05465</td></tr><tr><td>metrics/recall</td><td>0.10825</td></tr><tr><td>train/box_loss</td><td>0.07579</td></tr><tr><td>train/cls_loss</td><td>0.02096</td></tr><tr><td>train/obj_loss</td><td>0.12232</td></tr><tr><td>val/box_loss</td><td>0.09</td></tr><tr><td>val/cls_loss</td><td>0.0196</td></tr><tr><td>val/obj_loss</td><td>0.06213</td></tr><tr><td>x/lr0</td><td>0.0002</td></tr><tr><td>x/lr1</td><td>0.0002</td></tr><tr><td>x/lr2</td><td>0.0903</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 398 media file(s), 1 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">testtest</strong>: <a href=\"https://wandb.ai/dddetection/YOLOv5/runs/1e0ts3pl\" target=\"_blank\">https://wandb.ai/dddetection/YOLOv5/runs/1e0ts3pl</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20220217_160141-1e0ts3pl\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1mruns\\train\\testtest2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "%run -i ../src/train.py --data ../data/cyolo.yaml --batch-size 20 --epochs 25 --bcc_epoch 0 --name testtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3ff31f1-e3c4-4cf3-9cb9-cf16fe9b85be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=../data/iid-tvt.yaml, weights=['runs/train/Expset1_all_cyolo/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=Expset1_all_cyolo_test, exist_ok=False, half=False\n",
      "                 all         10         32      0.566      0.182     0.0328    0.00475\n",
      "           bone-loss         10         11      0.133      0.364     0.0649    0.00938\n",
      "       dental-caries         10         21          1          0    0.00063   0.000126\n",
      "Speed: 1.6ms pre-process, 24.4ms inference, 3.9ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\val\\Expset1_all_cyolo_test\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-1-18 torch 1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 3090, 24575.5MB)\n",
      "\n",
      "Fusing layers... \n",
      "C:\\Users\\rb01243\\Anaconda3\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning '..\\data\\datasets\\iid-tvt\\labels\\test.cache' images and labels... 10 found, 0 missing, 0 empty, 0 corrupted: 100%|##########| 10/10 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning '..\\data\\datasets\\iid-tvt\\labels\\test.cache' images and labels... 10 found, 0 missing, 0 empty, 0 corrupted: 100%|##########| 10/10 [00:00<?, ?it/s]\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|##########| 1/1 [00:05<00:00,  5.97s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|##########| 1/1 [00:05<00:00,  5.97s/it]\n"
     ]
    }
   ],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "!python ../src/val.py --weights runs/train/Expset1_all_cyolo/weights/best.pt --data ../data/iid-tvt.yaml --task test --name Expset1_all_cyolo_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ecd43c-73f7-4095-a86c-9ada6aed3837",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'save_one_box' from 'utils.general' (C:\\Users\\rb01243\\OneDrive - University of Surrey\\Documents\\GitHub\\dental_disease\\yolov5-master\\utils\\general.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\dental_disease\\src\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0myaml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcyolo_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_with_bcc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVOL_ID_MAP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSINGLE_VOL_ID_MAP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[0mconvert_target_volunteers_yolo2bcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_file_volunteers_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_volunteers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mnn_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_bcc_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_param_confusion_matrices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\dental_disease\\src\\cyolo_utils\\train_with_bcc.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneral\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxywh2xyxy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneral\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincrement_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdetect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\dental_disease\\src\\detect.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mattempt_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLoadStreams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLoadImages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneral\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_img_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_requirements\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_imshow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolorstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_ascii\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_max_suppression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mapply_classifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_coords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxyxy2xywh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrip_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_logging\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincrement_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_one_box\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplots\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAnnotator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'save_one_box' from 'utils.general' (C:\\Users\\rb01243\\OneDrive - University of Surrey\\Documents\\GitHub\\dental_disease\\yolov5-master\\utils\\general.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "# PROJ_PATH = '..'\n",
    "# sys.path.append(PROJ_PATH)\n",
    "# from src.data_preparer import prepare_data\n",
    "#os.chdir(origDir)\n",
    "#os.chdir(os.getcwd()+'/yolov5_master')\n",
    "\n",
    "#%run -i train.py --data ../data/iid-tvt.yaml --batch-size 20 --epochs 18 --weights models/yolov5s.pt\n",
    "#%run -i src/train.py --data data/iid-tvt.yaml --batch-size 20 --epochs 18 --bcc_epoch -1 --cfg src/models/yolov5s.yaml\n",
    "#%run -i yolov5_master/train.py --data data/iid-tvt.yaml --batch-size 20 --epochs 18 --cfg yolov5_master/models/yolov5s.yaml\n",
    "#%run -i train.py --data data/iid-tvt.yaml --batch-size 20 --epochs 18 --weights models/yolov5s.pt --bcc_epoch -1 yolov5_master/train.py yolov5_master/models/yolov5s.pt\n",
    "\n",
    "#os.chdir(origDir) \n",
    "\n",
    "# SRC_PATH = os.path.join(PROJ_PATH, 'src')\n",
    "# DATA_PATH = os.path.join(PROJ_PATH, 'data/datasets')\n",
    "\n",
    "# # data_modes = ['sty', 'stcy']\n",
    "# # train_ratios = (0.7, 0.2, 0.1)\n",
    "# # data_path = DATA_PATH\n",
    "# # for mode in data_modes:\n",
    "# #     prepare_data(mode, train_ratios, data_path)\n",
    "\n",
    "\n",
    "# data = '../data/iid-tvt.yaml'\n",
    "# #data = '../data/cyolo.yaml'\n",
    "# batch_size = 20 # Change this to number of train images\n",
    "# epochs = 20\n",
    "# bcc_epoch = -1 # Involve BCC from epoch number \"bcc_epoch\". Set to -1 for no BCC. 0 for all BCC.\n",
    "# exp_num = 10002\n",
    "# name = f'exp{exp_num}'\n",
    "\n",
    "# print(SRC_PATH)\n",
    "#wandb.init(project=\"cyolo\", entity=\"dddetection\")\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "#torch. set_printoptions(profile=\"full\")\n",
    "#torch. set_printoptions(profile=\"default\")\n",
    "%run -i ../src/train.py --data ../data/iid-tvt.yaml --batch-size 20 --epochs 20 --bcc_epoch -1 --name iid\n",
    "#%run -i ../src/train.py --data ../data/coco2.yaml --batch-size 18 --epochs 2 --bcc_epoch -1 --name testCOCO1\n",
    "\n",
    "# !python $SRC_PATH/train.py --data $data \\\n",
    "#                            --batch-size $batch_size \\\n",
    "#                            --epochs $epochs \\\n",
    "#                            --bcc_epoch $bcc_epoch \\\n",
    "#                            --name $name \\\n",
    "#                            --exist-ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c572d3-3bf0-4f14-85e4-3306864bf515",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71a7334-bcaa-4460-bc66-86ffcb893705",
   "metadata": {},
   "source": [
    "{ analysis goes here }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14ebd1e-c827-4212-99b8-7b7c89eb4fbf",
   "metadata": {},
   "source": [
    "# Experiment 2 (Crowd RCNN)\n",
    "\n",
    "### This section runs the experiments, prints results, and plots graphs for both dataset using the Crowd RCNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4acab0-a0a4-4db6-a0d1-f30c5cdb7f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../Crowd-R-CNN-master/trainval_net.py --dataset ../data/datasets/bcc-tvt/ --batch_size 20 --epochs 80 --name Expset1_all_RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755e608b-2cb4-4c0f-ae55-64c56438f2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dc3123b-d1df-451d-b577-da40fe0d31fa",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666e3ed-7714-4576-9513-76701ab6e9ab",
   "metadata": {},
   "source": [
    "{ analysis goes here }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ce7d6-a098-4f0a-a72e-9d4a99afe6d3",
   "metadata": {},
   "source": [
    "# Experiment 3 (YoloV5 IID Annotators)\n",
    "\n",
    "### This section runs the experiments, prints results, and plots graphs for all annotators where their labels are treated as ground truth labels, using the YoloV5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe52f8cb-982c-4434-a61b-7c47441763c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-2-8 torch 1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 3090, 24575.5MB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, obj=1.0, cls=0.5, cls_pw=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mbcc_epoch=-1, confusion_matrix_diagonal_prior_hyp=0.1, convergence_threshold_hyp=1e-06, qtfilter_epoch=-1, qt_thres_mode=, qt_thres=0.0, hybrid_entropy_thres=0.0, hybrid_conf_thres=0.0, weights=yolov5s.pt, cfg=, data=../data/iid-tvt.yaml, hyp=../data/hyps/hyp.scratch.yaml, epochs=80, batch_size=20, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=Expset1_iid_yolov5, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=1100\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "device:  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 270 layers, 7025023 parameters, 7025023 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 344/350 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00046875\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation is:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '..\\data\\datasets\\iid-tvt\\labels\\train.cache' images and labels... 262 found, 18 missing, 0 empty, 0 corrupted: 100%|██████████| 280/280 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\data\\datasets\\iid-tvt\\labels\\val.cache' images and labels... 67 found, 13 missing, 0 empty, 0 corrupted: 100%|██████████| 80/80 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\Expset1_iid_yolov52\u001b[0m\n",
      "Starting training for 80 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "Only YOLO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 6.02, Best Possible Recall (BPR) = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/79     4.52G    0.1187   0.04704   0.02723       130       640: 100%|██████████| 14/14 [00:06<00:00,  2.13it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:01<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220    0.00201    0.00258   0.000431   8.51e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/14 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to Create train results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "Only YOLO\n",
      "      1/79     4.51G    0.1116   0.04931    0.0242       109       640: 100%|██████████| 14/14 [00:02<00:00,  4.96it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 2/2 [00:01<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         80        220    0.00106     0.0387   0.000595   9.44e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/14 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to Create train results\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "abs(): argument 'input' (position 1) must be Tensor, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    758\u001b[0m     \u001b[1;31m# opt.device = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;31m# opt.name = 'test'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;31m#torch.cuda.empty_cache()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(opt)\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;31m# Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevolve\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mWORLD_SIZE\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mRANK\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Destroying process group... '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy_process_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(hyp, opt, device, callbacks)\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_lb\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mold_lb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mold_lb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbcc_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'convergence_threshold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Convergence reached!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: abs(): argument 'input' (position 1) must be Tensor, not float"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "%run -i ../src/train.py --data ../data/iid-tvt.yaml --batch-size 20 --epochs 80 --bcc_epoch -1 --name Expset1_iid_yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "646a8125-cc28-41bc-a63f-d22e5ab827f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=../data/iid-tvt.yaml, weights=['runs/train/Expset1_iid_yolov5/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=Expset1_iid_yolov5_test, exist_ok=False, half=False\n",
      "                 all         10         32      0.749     0.0455     0.0466     0.0144\n",
      "           bone-loss         10         11      0.498     0.0909     0.0909     0.0283\n",
      "       dental-caries         10         21          1          0    0.00228   0.000457\n",
      "Speed: 0.7ms pre-process, 3.0ms inference, 2.0ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\val\\Expset1_iid_yolov5_test\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-1-18 torch 1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 3090, 24575.5MB)\n",
      "\n",
      "Fusing layers... \n",
      "C:\\Users\\rb01243\\Anaconda3\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning '..\\data\\datasets\\iid-tvt\\labels\\test.cache' images and labels... 10 found, 0 missing, 0 empty, 0 corrupted: 100%|##########| 10/10 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning '..\\data\\datasets\\iid-tvt\\labels\\test.cache' images and labels... 10 found, 0 missing, 0 empty, 0 corrupted: 100%|##########| 10/10 [00:00<?, ?it/s]\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|##########| 1/1 [00:03<00:00,  3.04s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|##########| 1/1 [00:03<00:00,  3.04s/it]\n"
     ]
    }
   ],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "!python ../src/val.py --weights runs/train/Expset1_iid_yolov5/weights/best.pt --data ../data/iid-tvt.yaml --task test --name Expset1_iid_yolov5_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc2c2e-f4e2-4d9b-86d2-afb1a866bc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db276a6f-4959-4898-893e-9defa8128161",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b14cdd-1de6-41f2-ae6a-bede589625e5",
   "metadata": {},
   "source": [
    "{ analysis goes here }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bd9df0-d96d-4939-84a6-567a72a39ecb",
   "metadata": {},
   "source": [
    "# Experiment 4 (YoloV5 Agregation Preprocessing)\n",
    "\n",
    "### This section runs the experiments, prints results, and plots graphs for both dataset where ground truth labels are agregated into ground truth labels. This experiment also uses YoloV5 as the object detection algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b377a7a-47fa-4bb5-a5e5-1e58aa0f2679",
   "metadata": {},
   "source": [
    "## 4.2  CSexp (Dataset 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65118089-4e0a-4481-9a27-224038669ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce1485f-a77a-4d54-adc1-f3fc5558cc82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c53a4e0-edf1-4d61-881c-0cfe4d711593",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ee798-6531-4ab1-935d-d7fd70de2e37",
   "metadata": {},
   "source": [
    "{ analysis goes here }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6920cf-b0a9-44dd-bd23-d42ee0cbbbc9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee0db88c-d29a-408b-bbef-f53be7847017",
   "metadata": {},
   "source": [
    "# Conclusion Experiment Set 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9820fa65-e57a-4a99-90c9-1a9850c3b9fe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5872aa92-309b-400f-b485-f2e4dc00b0e2",
   "metadata": {},
   "source": [
    "# EXPERIMENT SET 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e4daa5-6ef8-471d-88ca-38d1a1cf0126",
   "metadata": {},
   "source": [
    "# Experiment 1 (Crowd Yolo Model)\n",
    "\n",
    "### This section runs the experiments, prints results, and plots graphs for both dataset using the Crowd Yolo model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da81d5d6-0d14-400f-9d9c-943ff730f6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-2-8 torch 1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 3090, 24575.5MB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, obj=1.0, cls=0.5, cls_pw=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mbcc_epoch=0, confusion_matrix_diagonal_prior_hyp=0.1, convergence_threshold_hyp=1e-06, qtfilter_epoch=-1, qt_thres_mode=, qt_thres=0.0, hybrid_entropy_thres=0.0, hybrid_conf_thres=0.0, weights=yolov5s.pt, cfg=, data=../data/All_Volunteers_Calc_Removed_Crowdsourced.yaml, hyp=../data/hyps/hyp.scratch.yaml, epochs=20, batch_size=25, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=test, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=1100\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "device:  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdddetection\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/dddetection/YOLOv5/runs/21656yd7\" target=\"_blank\">test</a></strong> to <a href=\"https://wandb.ai/dddetection/YOLOv5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "C:\\Users\\rb01243\\Anaconda3\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 270 layers, 7025023 parameters, 7025023 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 344/350 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0005859375\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation is:  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '..\\data\\datasets\\All_Volunteers_Calc_Removed_Crowdsourced\\labels\\train.cache' images and labels... 1552 found, 0 missing, 0 empty, 1 corrupted: 100%|██████████| 1552/1552 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label ..\\data\\datasets\\All_Volunteers_Calc_Removed_Crowdsourced\\images\\train\\Unknown-X-20200130-084742-XLGSYPPPTEXC-0.JPG: non-normalized or out of bounds coordinate labels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\data\\datasets\\All_Volunteers_Calc_Removed_Crowdsourced\\labels\\val.cache' images and labels... 388 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 388/388 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\test3\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.37, Best Possible Recall (BPR) = 0.9985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "There were no tensor arguments to this function (e.g., you passed an empty list of Tensors), but no fallback function is registered for schema aten::_cat.  This usually means that this function requires a non-empty list of Tensors, or that you (the operator writer) forgot to register a fallback function.  Available functions are [CPU, CUDA, QuantizedCPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten\\src\\ATen\\RegisterCPU.cpp:18433 [kernel]\nCUDA: registered at aten\\src\\ATen\\RegisterCUDA.cpp:26496 [kernel]\nQuantizedCPU: registered at aten\\src\\ATen\\RegisterQuantizedCPU.cpp:1068 [kernel]\nBackendSelect: fallthrough registered at ..\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ..\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ..\\aten\\src\\ATen\\ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ..\\aten\\src\\ATen\\native\\NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ..\\torch\\csrc\\autograd\\generated\\TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ..\\aten\\src\\ATen\\autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ..\\aten\\src\\ATen\\autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ..\\aten\\src\\ATen\\BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ..\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m \u001b[1;31m#torch.cuda.empty_cache()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(opt)\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;31m# Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevolve\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mWORLD_SIZE\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mRANK\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Destroying process group... '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy_process_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(hyp, opt, device, callbacks)\u001b[0m\n\u001b[0;32m    343\u001b[0m                 \u001b[0mtarget_volunteers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_volunteers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[0mtarget_volunteers_bcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvigcwh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_target_volunteers_yolo2bcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_volunteers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_anchor_choices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_ratios\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvol_id_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m                 \u001b[0mtarget_volunteers_bcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_volunteers_bcc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# adds to cuda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[1;31m# batch_cstargets_bcc = (cstargets_bcc[dataset.batch == i]).to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\cyolo_utils\\train_with_bcc.py\u001b[0m in \u001b[0;36mconvert_target_volunteers_yolo2bcc\u001b[1;34m(target_volunteers, Na, Nc, G, batch_size, vol_id_map)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0mtargets_per_i_bcc_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets_per_i_bcc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[0mtarget_volunteers_bcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets_per_i_bcc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m     \u001b[0mvigcwh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvigcwh_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtarget_volunteers_bcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvigcwh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: There were no tensor arguments to this function (e.g., you passed an empty list of Tensors), but no fallback function is registered for schema aten::_cat.  This usually means that this function requires a non-empty list of Tensors, or that you (the operator writer) forgot to register a fallback function.  Available functions are [CPU, CUDA, QuantizedCPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten\\src\\ATen\\RegisterCPU.cpp:18433 [kernel]\nCUDA: registered at aten\\src\\ATen\\RegisterCUDA.cpp:26496 [kernel]\nQuantizedCPU: registered at aten\\src\\ATen\\RegisterQuantizedCPU.cpp:1068 [kernel]\nBackendSelect: fallthrough registered at ..\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ..\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ..\\aten\\src\\ATen\\ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ..\\aten\\src\\ATen\\native\\NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ..\\torch\\csrc\\autograd\\generated\\VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ..\\torch\\csrc\\autograd\\generated\\TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ..\\aten\\src\\ATen\\autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ..\\aten\\src\\ATen\\autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ..\\aten\\src\\ATen\\BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ..\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "%run -i ../src/train.py --data ../data/All_Volunteers_Calc_Removed_Crowdsourced.yaml --batch-size 25 --epochs 50 --bcc_epoch 0 --device 0 --name ex1_Zoon_with_Calc\n",
    "#--batch-size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29764ba0-e9da-4de1-be59-ac5b32db662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-2-8 torch 1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 3090, 24575.5MB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, obj=1.0, cls=0.5, cls_pw=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mbcc_epoch=0, confusion_matrix_diagonal_prior_hyp=0.1, convergence_threshold_hyp=1e-06, qtfilter_epoch=-1, qt_thres_mode=, qt_thres=0.0, hybrid_entropy_thres=0.0, hybrid_conf_thres=0.0, weights=yolov5s.pt, cfg=, data=../data/All_Volunteers_Calc_Removed_Crowdsourced.yaml, hyp=../data/hyps/hyp.scratch.yaml, epochs=25, batch_size=25, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=test, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=1100, batch=25\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "device:  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdddetection\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/dddetection/YOLOv5/runs/2mv8853a\" target=\"_blank\">test</a></strong> to <a href=\"https://wandb.ai/dddetection/YOLOv5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "C:\\Users\\rb01243\\Anaconda3\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 270 layers, 7025023 parameters, 7025023 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 344/350 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0005859375\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation is:  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '..\\data\\datasets\\All_Volunteers_Calc_Removed_Crowdsourced\\labels\\train.cache' images and labels... 1552 found, 0 missing, 0 empty, 1 corrupted: 100%|██████████| 1552/1552 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label ..\\data\\datasets\\All_Volunteers_Calc_Removed_Crowdsourced\\images\\train\\Unknown-X-20200130-084742-XLGSYPPPTEXC-0.JPG: non-normalized or out of bounds coordinate labels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\data\\datasets\\All_Volunteers_Calc_Removed_Crowdsourced\\labels\\val.cache' images and labels... 388 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 388/388 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels... \n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.37, Best Possible Recall (BPR) = 0.9985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\test2\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_volunteers_bcc:  tensor([[[2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         ...,\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         ...,\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         ...,\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         ...,\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         ...,\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         ...,\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.],\n",
      "         [2., 2., 2.,  ..., 2., 2., 2.]]], device='cuda:0')\n",
      "target_volunteers_bcc size:  torch.Size([25, 25200, 193])\n",
      "batch_pred_bcc:  tensor([[[-8.32899e+00, -8.08883e+00, -4.88401e-04],\n",
      "         [-8.24789e+00, -7.81210e+00, -4.88401e-04],\n",
      "         [-7.70726e+00, -7.46833e+00, -9.77040e-04],\n",
      "         ...,\n",
      "         [-5.45024e+00, -5.35538e+00, -8.82791e-03],\n",
      "         [-5.67679e+00, -5.68399e+00, -6.85941e-03],\n",
      "         [-5.39834e+00, -5.62649e+00, -8.33542e-03]],\n",
      "\n",
      "        [[-8.67924e+00, -8.57010e+00, -4.88401e-04],\n",
      "         [-8.58038e+00, -8.28180e+00, -4.88401e-04],\n",
      "         [-8.04470e+00, -7.93970e+00, -4.88401e-04],\n",
      "         ...,\n",
      "         [-5.13154e+00, -5.00279e+00, -1.27766e-02],\n",
      "         [-5.21260e+00, -5.12808e+00, -1.12940e-02],\n",
      "         [-5.19633e+00, -5.42692e+00, -9.81362e-03]],\n",
      "\n",
      "        [[-8.20185e+00, -8.10235e+00, -4.88401e-04],\n",
      "         [-8.09623e+00, -7.81200e+00, -4.88401e-04],\n",
      "         [-7.57446e+00, -7.50223e+00, -9.77040e-04],\n",
      "         ...,\n",
      "         [-5.19936e+00, -5.11088e+00, -1.17880e-02],\n",
      "         [-5.35227e+00, -5.35691e+00, -9.32065e-03],\n",
      "         [-5.21228e+00, -5.56739e+00, -9.32065e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-8.56747e+00, -8.46334e+00, -4.88401e-04],\n",
      "         [-8.46789e+00, -8.19587e+00, -4.88401e-04],\n",
      "         [-7.96631e+00, -7.85366e+00, -9.77040e-04],\n",
      "         ...,\n",
      "         [-5.25868e+00, -5.14475e+00, -1.12940e-02],\n",
      "         [-5.41762e+00, -5.41644e+00, -8.82791e-03],\n",
      "         [-5.15251e+00, -5.51295e+00, -9.81362e-03]],\n",
      "\n",
      "        [[-8.70239e+00, -8.62390e+00, -4.88401e-04],\n",
      "         [-8.59355e+00, -8.35476e+00, -4.88401e-04],\n",
      "         [-8.10638e+00, -8.11757e+00, -4.88401e-04],\n",
      "         ...,\n",
      "         [-5.16752e+00, -5.05122e+00, -1.22821e-02],\n",
      "         [-5.31229e+00, -5.29015e+00, -9.81362e-03],\n",
      "         [-5.17254e+00, -5.50347e+00, -9.81362e-03]],\n",
      "\n",
      "        [[-8.44552e+00, -8.24817e+00, -4.88401e-04],\n",
      "         [-8.34598e+00, -7.97373e+00, -4.88401e-04],\n",
      "         [-7.84468e+00, -7.80118e+00, -9.77040e-04],\n",
      "         ...,\n",
      "         [-5.25479e+00, -5.19254e+00, -1.08003e-02],\n",
      "         [-5.41882e+00, -5.51055e+00, -8.33542e-03],\n",
      "         [-5.08261e+00, -5.49032e+00, -1.03068e-02]]], device='cuda:0', grad_fn=<LogBackward0>)\n",
      "batch_pred_bcc.size():  torch.Size([25, 25200, 3])\n",
      "batch_pcm['variational']:  tensor([[[1.10000, 1.10000, 1.10000,  ..., 1.10000, 1.10000, 1.10000],\n",
      "         [1.00000, 1.00000, 1.00000,  ..., 1.00000, 1.00000, 1.00000],\n",
      "         [1.00000, 1.00000, 1.00000,  ..., 1.00000, 1.00000, 1.00000]],\n",
      "\n",
      "        [[1.00000, 1.00000, 1.00000,  ..., 1.00000, 1.00000, 1.00000],\n",
      "         [1.10000, 1.10000, 1.10000,  ..., 1.10000, 1.10000, 1.10000],\n",
      "         [1.00000, 1.00000, 1.00000,  ..., 1.00000, 1.00000, 1.00000]],\n",
      "\n",
      "        [[1.00000, 1.00000, 1.00000,  ..., 1.00000, 1.00000, 1.00000],\n",
      "         [1.00000, 1.00000, 1.00000,  ..., 1.00000, 1.00000, 1.00000],\n",
      "         [1.10000, 1.10000, 1.10000,  ..., 1.10000, 1.10000, 1.10000]]], device='cuda:0', dtype=torch.float64)\n",
      "batch_pcm['variational'].size():  torch.Size([3, 3, 193])\n",
      "batch_pcm['prior']:  tensor([[[1.10000, 1.10000, 1.10000,  ..., 1.10000, 1.10000, 1.10000],\n",
      "         [1.00000, 1.00000, 1.00000,  ..., 1.00000, 1.00000, 1.00000],\n",
      "         [1.00000, 1.00000, 1.00000,  ..., 1.00000, 1.00000, 1.00000]],\n",
      "\n",
      "        [[1.00000, 1.00000, 1.00000,  ..., 1.00000, 1.00000, 1.00000],\n",
      "         [1.10000, 1.10000, 1.10000,  ..., 1.10000, 1.10000, 1.10000],\n",
      "         [1.00000, 1.00000, 1.00000,  ..., 1.00000, 1.00000, 1.00000]],\n",
      "\n",
      "        [[1.00000, 1.00000, 1.00000,  ..., 1.00000, 1.00000, 1.00000],\n",
      "         [1.00000, 1.00000, 1.00000,  ..., 1.00000, 1.00000, 1.00000],\n",
      "         [1.10000, 1.10000, 1.10000,  ..., 1.10000, 1.10000, 1.10000]]], device='cuda:0', dtype=torch.float64)\n",
      "batch_pcm['prior'].size():  torch.Size([3, 3, 193])\n",
      "batch_qtargets tensor([[[3.31164e-17, 4.21065e-17, 1.00000e+00],\n",
      "         [3.59146e-17, 5.55307e-17, 1.00000e+00],\n",
      "         [6.16980e-17, 7.83491e-17, 1.00000e+00],\n",
      "         ...,\n",
      "         [5.94139e-16, 6.53272e-16, 1.00000e+00],\n",
      "         [4.72779e-16, 4.69387e-16, 1.00000e+00],\n",
      "         [6.25490e-16, 4.97894e-16, 1.00000e+00]],\n",
      "\n",
      "        [[2.33309e-17, 2.60211e-17, 1.00000e+00],\n",
      "         [2.57549e-17, 3.47163e-17, 1.00000e+00],\n",
      "         [4.40062e-17, 4.88772e-17, 1.00000e+00],\n",
      "         ...,\n",
      "         [8.20412e-16, 9.33145e-16, 1.00000e+00],\n",
      "         [7.55407e-16, 8.22016e-16, 1.00000e+00],\n",
      "         [7.66671e-16, 6.08786e-16, 1.00000e+00]],\n",
      "\n",
      "        [[3.76061e-17, 4.15411e-17, 1.00000e+00],\n",
      "         [4.17954e-17, 5.55358e-17, 1.00000e+00],\n",
      "         [7.04614e-17, 7.57395e-17, 1.00000e+00],\n",
      "         ...,\n",
      "         [7.65829e-16, 8.36695e-16, 1.00000e+00],\n",
      "         [6.55648e-16, 6.52614e-16, 1.00000e+00],\n",
      "         [7.54163e-16, 5.28745e-16, 1.00000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.60895e-17, 2.89526e-17, 1.00000e+00],\n",
      "         [2.88212e-17, 3.78317e-17, 1.00000e+00],\n",
      "         [4.76169e-17, 5.32959e-17, 1.00000e+00],\n",
      "         ...,\n",
      "         [7.21387e-16, 8.08433e-16, 1.00000e+00],\n",
      "         [6.13842e-16, 6.14573e-16, 1.00000e+00],\n",
      "         [8.01016e-16, 5.58602e-16, 1.00000e+00]],\n",
      "\n",
      "        [[2.27967e-17, 2.46581e-17, 1.00000e+00],\n",
      "         [2.54184e-17, 3.22733e-17, 1.00000e+00],\n",
      "         [4.13741e-17, 4.09133e-17, 1.00000e+00],\n",
      "         ...,\n",
      "         [7.91032e-16, 8.88594e-16, 1.00000e+00],\n",
      "         [6.82724e-16, 6.97998e-16, 1.00000e+00],\n",
      "         [7.85140e-16, 5.63912e-16, 1.00000e+00]],\n",
      "\n",
      "        [[2.94732e-17, 3.59048e-17, 1.00000e+00],\n",
      "         [3.25582e-17, 4.72420e-17, 1.00000e+00],\n",
      "         [5.37762e-17, 5.61681e-17, 1.00000e+00],\n",
      "         ...,\n",
      "         [7.23834e-16, 7.70330e-16, 1.00000e+00],\n",
      "         [6.12812e-16, 5.59097e-16, 1.00000e+00],\n",
      "         [8.59417e-16, 5.71657e-16, 1.00000e+00]]], device='cuda:0')\n",
      "batch_qtargets size torch.Size([25, 25200, 3])\n",
      "batch_lb tensor(-176150.07812, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/24     9.76G         0   0.02266         0       414       640:   2%|▏         | 1/63 [00:24<25:28, 24.65s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to find a valid cuDNN algorithm to run convolution",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    756\u001b[0m     \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m \u001b[1;31m#torch.cuda.empty_cache()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(opt)\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;31m# Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevolve\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mWORLD_SIZE\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mRANK\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Destroying process group... '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy_process_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(hyp, opt, device, callbacks)\u001b[0m\n\u001b[0;32m    374\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbcc_flag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m                     \u001b[0mbatch_pred_yolo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform_format_flag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# y_hat_yolo # gets the cyolo prdictions for the batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m                     \u001b[0mbatch_pred_bcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myolo2bcc_newer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_pred_yolo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# y_hat_bcc # batch_conf # converts yolo predictions in a format that is readable by bcc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'target_volunteers_bcc: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_volunteers_bcc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\cyolo_utils\\train_with_bcc.py\u001b[0m in \u001b[0;36mnn_predict\u001b[1;34m(model, x, imgsz, offgrid_translate_flag, normalize_flag, transform_format_flag)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;31m# update of approximating posterior for the true labels and confusion matrices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;31m# get current predictions from a neural network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moffgrid_translate_flag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[1;31m# TODO: A quickfix here is to force-translate any point lying outside the grid to the nearest grid cell.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\models\\yolo.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, augment, profile, visualize)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maugment\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_augment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# augmented inference, None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# single-scale inference, train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward_augment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\models\\yolo.py\u001b[0m in \u001b[0;36mforward_once\u001b[1;34m(self, x, profile, visualize)\u001b[0m\n\u001b[0;32m    153\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{dt[-1]:10.2f} {o:10.2f} {m.np:10.0f}  {m.type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# save output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\models\\common.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\models\\common.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\models\\common.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward_fuse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 442\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to find a valid cuDNN algorithm to run convolution"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "%run -i ../src/train.py --data ../data/All_Volunteers_Calc_Removed_testtesttest_Crowdsourced.yaml --batch-size 25 --epochs 20 --bcc_epoch 0 --device 0 --name testtestSmallZoon\n",
    "#--batch-size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2f983b-a95a-49f9-a539-157bb1df1a96",
   "metadata": {},
   "source": [
    "## 1.1  CSall (Dataset 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "527fb3fa-59c8-4aa7-a7bb-fc26805b76ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-2-8 torch 1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 3090, 24575.5MB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, obj=1.0, cls=0.5, cls_pw=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mbcc_epoch=0, confusion_matrix_diagonal_prior_hyp=0.1, convergence_threshold_hyp=1e-06, qtfilter_epoch=-1, qt_thres_mode=, qt_thres=0.0, hybrid_entropy_thres=0.0, hybrid_conf_thres=0.0, weights=yolov5s.pt, cfg=, data=../data/All_Volunteers_Calc_Removed_100min_test_Crowdsourced.yaml, hyp=../data/hyps/hyp.scratch.yaml, epochs=25, batch_size=25, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=test_100min_labels, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=1100\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "device:  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdddetection\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/dddetection/YOLOv5/runs/1oepe5kc\" target=\"_blank\">test_100min_labels</a></strong> to <a href=\"https://wandb.ai/dddetection/YOLOv5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "C:\\Users\\rb01243\\Anaconda3\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 270 layers, 7025023 parameters, 7025023 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 344/350 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0005859375\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation is:  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '..\\data\\datasets\\All_Volunteers_Calc_Removed_100min_test_Crowdsourced\\labels\\train' images and labels...1151 found, 0 missing, 0 empty, 1 corrupted: 100%|██████████| 1151/1151 [00:04<00:00, 232.26it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label ..\\data\\datasets\\All_Volunteers_Calc_Removed_100min_test_Crowdsourced\\images\\train\\Unknown-X-20200130-084742-XLGSYPPPTEXC-0.JPG: non-normalized or out of bounds coordinate labels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ..\\data\\datasets\\All_Volunteers_Calc_Removed_100min_test_Crowdsourced\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\data\\datasets\\All_Volunteers_Calc_Removed_100min_test_IID\\labels\\val' images and labels...983 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 983/983 [00:05<00:00, 192.02it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: ..\\data\\datasets\\All_Volunteers_Calc_Removed_100min_test_IID\\labels\\val.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\test_100min_labels\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.30, Best Possible Recall (BPR) = 0.9991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/24     12.5G         0   0.01336         0       169       640: 100%|██████████| 46/46 [00:45<00:00,  1.00it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:07<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983       2631    0.00113      0.034   0.000493   0.000102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:10<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270    0.00387     0.0386    0.00188   0.000379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      1/24     16.5G         0  0.005267         0       169       640: 100%|██████████| 46/46 [00:41<00:00,  1.10it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:06<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983       2631    0.00135     0.0482   0.000691   0.000134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:07<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270     0.0046     0.0277    0.00221   0.000447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      2/24     16.5G         0  0.002983         0       169       640: 100%|██████████| 46/46 [00:41<00:00,  1.11it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:04<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983       2631    0.00269     0.0132    0.00108   0.000225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:06<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270    0.00563     0.0634    0.00255   0.000516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      3/24     16.5G         0  0.001952         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.13it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:05<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983       2631    0.00294     0.0151      0.001   0.000198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:06<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270    0.00815     0.0196    0.00261   0.000544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      4/24     16.5G         0  0.001384         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.13it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:04<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983       2631    0.00389    0.00463    0.00105    0.00021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:06<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270    0.00548     0.0559    0.00321   0.000731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      5/24     16.5G         0  0.001035         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.14it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:05<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983       2631    0.00239     0.0222    0.00129   0.000271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:06<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270    0.00674     0.0223    0.00366   0.000792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      6/24     16.5G         0 0.0008039         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.13it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:04<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983       2631    0.00305     0.0119    0.00157   0.000316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:06<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270    0.00858     0.0106    0.00466   0.000922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      7/24     16.5G         0 0.0006561         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.15it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:05<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983       2631    0.00288    0.00541    0.00147   0.000204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:05<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270     0.0093    0.00579    0.00498    0.00111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      8/24     16.5G         0 0.0005386         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.14it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:03<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983       2631    0.00245    0.00241    0.00134   0.000205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:05<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270    0.00878    0.00264     0.0048   0.000942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "      9/24     16.5G         0 0.0004485         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.15it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:04<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983       2631     0.0032    0.00176    0.00163   0.000296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:05<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270     0.0169    0.00257    0.00891    0.00198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     10/24     16.5G         0   0.00038         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.13it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:02<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983       2631     0.0054    0.00176    0.00271   0.000545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:05<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270     0.0235    0.00191     0.0122    0.00267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     11/24     16.5G         0 0.0003271         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.14it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:03<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983       2631    0.00251   0.000457    0.00126   0.000126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:05<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270     0.0174   0.000935    0.00888    0.00249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     12/24     16.5G         0 0.0002853         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.13it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:02<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983       2631    0.00481   0.000782    0.00248   0.000355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:05<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270     0.0177   0.000524    0.00896    0.00223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     13/24     16.5G         0 0.0002518         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.14it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:03<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983       2631    0.00689   0.000782    0.00347   0.000851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:05<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270     0.0181   0.000216    0.00916    0.00153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     14/24     16.5G         0 0.0002247         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.14it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:02<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983          0          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:05<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270     0.0122   0.000205    0.00616    0.00154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     15/24     16.5G         0 0.0002024         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.14it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:03<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983          0          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:05<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270     0.0196   0.000205    0.00994    0.00246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     16/24     16.5G         0 0.0001839         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.15it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:02<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983          0          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:05<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270     0.0152   0.000103    0.00786   0.000786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     17/24     16.5G         0 0.0001683         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.14it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:03<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983          0          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:05<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270     0.0208   0.000103     0.0107    0.00107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     18/24     16.5G         0 0.0001552         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.13it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:02<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983          0          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:05<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150          0          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     19/24     16.5G         0  0.000144         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.12it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:03<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983          0          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:04<00:00,  9.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270       0.05   0.000103     0.0256     0.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     20/24     16.5G         0 0.0001343         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.14it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:02<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983          0          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:05<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270      0.167   0.000103     0.0834    0.00834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     21/24     16.5G         0 0.0001268         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.14it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:03<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983          0          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:05<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150          0          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     22/24     16.5G         0 0.0001196         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.14it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:02<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983          0          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:05<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150       9270      0.167   0.000103     0.0834    0.00834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     23/24     16.5G         0 0.0001126         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.14it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:02<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983          0          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:05<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150          0          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n",
      "     24/24     16.5G         0 0.0001068         0       169       640: 100%|██████████| 46/46 [00:40<00:00,  1.14it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:02<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983          0          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 46/46 [00:05<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all       1150          0          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25 epochs completed in 0.355 hours.\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:02<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983          0          0          0          0          0\n",
      "\n",
      "Evaluating pycocotools mAP... saving runs\\train\\test_100min_labels\\_predictions.json...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m pycocotools not found and is required by YOLOv5, attempting auto-update...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Command 'pip install 'pycocotools'' returned non-zero exit status 1.\n",
      "pycocotools unable to run: No module named 'pycocotools'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 20/20 [00:02<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        983       2631    0.00279   0.000326    0.00142   0.000425\n",
      "\n",
      "Evaluating pycocotools mAP... saving runs\\train\\test_100min_labels\\_predictions.json...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m pycocotools not found and is required by YOLOv5, attempting auto-update...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Command 'pip install 'pycocotools'' returned non-zero exit status 1.\n",
      "pycocotools unable to run: No module named 'pycocotools'\n",
      "Optimizer stripped from runs\\train\\test_100min_labels\\weights\\last.pt, 14.3MB\n",
      "Optimizer stripped from runs\\train\\test_100min_labels\\weights\\best.pt, 14.3MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 33364... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 57.41MB of 57.41MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>metrics/mAP_0.5</td><td>▂▂▃▃▃▄▄▄▄▄▆▄▆█▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>▂▂▃▃▃▃▄▃▃▃▅▂▄█▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/precision</td><td>▂▂▄▄▅▃▄▄▃▄▆▄▆█▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/recall</td><td>▆█▃▃▂▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/box_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/cls_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/obj_loss</td><td>█▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/box_loss</td><td>▁▂██▇▆▆▅▄▄▄▄▅▅▆▅▄▃▂▁▁▁▂▁▁</td></tr><tr><td>val/cls_loss</td><td>▅█▄▄▄▄▃▄▄▄▄▃▃▂▂▂▂▂▃▃▂▃▂▁▁</td></tr><tr><td>val/obj_loss</td><td>▅▂▁▁▂▂▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇████</td></tr><tr><td>x/lr0</td><td>▁▂▃▄▅▅▆▇▇███████▇▇▆▆▆▅▅▅▅</td></tr><tr><td>x/lr1</td><td>▁▂▃▄▅▅▆▇▇███████▇▇▆▆▆▅▅▅▅</td></tr><tr><td>x/lr2</td><td>██▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>metrics/mAP_0.5</td><td>0.0</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>0.0</td></tr><tr><td>metrics/precision</td><td>0.0</td></tr><tr><td>metrics/recall</td><td>0.0</td></tr><tr><td>train/box_loss</td><td>0.0</td></tr><tr><td>train/cls_loss</td><td>0.0</td></tr><tr><td>train/obj_loss</td><td>0.00011</td></tr><tr><td>val/box_loss</td><td>0.122</td></tr><tr><td>val/cls_loss</td><td>0.02927</td></tr><tr><td>val/obj_loss</td><td>0.02397</td></tr><tr><td>x/lr0</td><td>0.00213</td></tr><tr><td>x/lr1</td><td>0.00213</td></tr><tr><td>x/lr2</td><td>0.00213</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 390 media file(s), 1 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">test_100min_labels</strong>: <a href=\"https://wandb.ai/dddetection/YOLOv5/runs/1oepe5kc\" target=\"_blank\">https://wandb.ai/dddetection/YOLOv5/runs/1oepe5kc</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20220214_120722-1oepe5kc\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1mruns\\train\\test_100min_labels\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "%run -i ../src/train.py --data ../data/All_Volunteers_Calc_Removed_100min_test_Crowdsourced.yaml --batch-size 25 --epochs 25 --bcc_epoch 0 --device 0 --name test_100min_labels\n",
    "#--batch-size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a473999-6457-4943-8cda-eb889f6978ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-2-8 torch 1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 3090, 24575.5MB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, obj=1.0, cls=0.5, cls_pw=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mbcc_epoch=0, confusion_matrix_diagonal_prior_hyp=0.1, convergence_threshold_hyp=1e-06, qtfilter_epoch=-1, qt_thres_mode=, qt_thres=0.0, hybrid_entropy_thres=0.0, hybrid_conf_thres=0.0, weights=yolov5s.pt, cfg=, data=../data/All_Volunteers_Crowdsourced.yaml, hyp=../data/hyps/hyp.scratch.yaml, epochs=10, batch_size=20, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=LargeDS_cyolo, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=1100\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "device:  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdddetection\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/dddetection/YOLOv5/runs/38vjmbgk\" target=\"_blank\">LargeDS_cyolo</a></strong> to <a href=\"https://wandb.ai/dddetection/YOLOv5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "C:\\Users\\rb01243\\Anaconda3\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 270 layers, 7027720 parameters, 7027720 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 344/350 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00046875\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '..\\data\\datasets\\All_Volunteers_Crowdsourced\\labels\\train.cache' images and labels... 1751 found, 0 missing, 0 empty, 1 corrupted: 100%|██████████| 1751/1751 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label ..\\data\\datasets\\All_Volunteers_Crowdsourced\\images\\train\\Unknown-X-20200130-084742-XLGSYPPPTEXC-0.JPG: non-normalized or out of bounds coordinate labels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\data\\datasets\\All_Volunteers_IID\\labels\\val.cache' images and labels... 947 found, 0 missing, 0 empty, 1 corrupted: 100%|██████████| 947/947 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label ..\\data\\datasets\\All_Volunteers_IID\\images\\val\\IX20191022_101649_0368_00003706.1a309d95dd140892a121.JPG: non-normalized or out of bounds coordinate labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\LargeDS_cyolo4\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "\n",
      "YOLO+BCC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.18, Best Possible Recall (BPR) = 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0/9     11.2G         0   0.01272         0       239       640:  72%|███████▏  | 63/88 [10:04<03:59,  9.59s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_opt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m \u001b[1;31m#torch.cuda.empty_cache()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(opt)\u001b[0m\n\u001b[0;32m    643\u001b[0m     \u001b[1;31m# Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevolve\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mWORLD_SIZE\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mRANK\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m             \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Destroying process group... '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy_process_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(hyp, opt, device, callbacks)\u001b[0m\n\u001b[0;32m    338\u001b[0m                 \u001b[0mtarget_volunteers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_volunteers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m                 \u001b[0mtarget_volunteers_bcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvigcwh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_target_volunteers_yolo2bcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_volunteers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_anchor_choices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_ratios\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvol_id_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m                 \u001b[0mtarget_volunteers_bcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_volunteers_bcc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m                 \u001b[1;31m# batch_cstargets_bcc = (cstargets_bcc[dataset.batch == i]).to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Surrey\\Documents\\GitHub\\miccai\\miccai_dental_disease\\src\\cyolo_utils\\train_with_bcc.py\u001b[0m in \u001b[0;36mconvert_target_volunteers_yolo2bcc\u001b[1;34m(target_volunteers, Na, Nc, G, batch_size, vol_id_map)\u001b[0m\n\u001b[0;32m    250\u001b[0m                 \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets_per_iv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;31m# w and h are ignored\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m                 \u001b[0mx_cell_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mg_frac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mg_frac\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m                 \u001b[0my_cell_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mg_frac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mg_frac\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 \u001b[0mgc_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_cell_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mg_frac\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx_cell_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "%run -i ../src/train.py --data ../data/All_Volunteers_Crowdsourced.yaml --batch-size 20 --epochs 100 --bcc_epoch 0 --device 0 --name LargeDS_cyolo\n",
    "#--batch-size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af04f64d-11fa-4678-a422-7b16a5eb734f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=../data/All_Volunteers_Crowdsourced.yaml, weights=['runs/train/Expset2_all_cyolo136/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=Expset2_all_cyolo136_test, exist_ok=False, half=False\n",
      "                 all        100        432    0.00203     0.0149    0.00103   0.000154\n",
      "     calculus-plaque        100        316    0.00251     0.0127    0.00127    0.00019\n",
      "       dental-caries        100        116    0.00155     0.0172   0.000786   0.000118\n",
      "Speed: 0.7ms pre-process, 6.1ms inference, 4.5ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\val\\Expset2_all_cyolo136_test\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-1-18 torch 1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 3090, 24575.5MB)\n",
      "\n",
      "Fusing layers... \n",
      "C:\\Users\\rb01243\\Anaconda3\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning '..\\data\\datasets\\All_Volunteers_Crowdsourced\\labels\\test' images and labels...:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning '..\\data\\datasets\\All_Volunteers_Crowdsourced\\labels\\test' images and labels...1 found, 0 missing, 0 empty, 0 corrupted:   1%|1         | 1/100 [00:03<05:10,  3.14s/it]\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning '..\\data\\datasets\\All_Volunteers_Crowdsourced\\labels\\test' images and labels...92 found, 0 missing, 0 empty, 0 corrupted:  92%|#########2| 92/100 [00:03<00:00, 39.92it/s]\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning '..\\data\\datasets\\All_Volunteers_Crowdsourced\\labels\\test' images and labels...100 found, 0 missing, 0 empty, 0 corrupted: 100%|##########| 100/100 [00:03<00:00, 30.82it/s]\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: ..\\data\\datasets\\All_Volunteers_Crowdsourced\\labels\\test.cache\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  25%|##5       | 1/4 [00:01<00:04,  1.46s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  50%|#####     | 2/4 [00:02<00:01,  1.01it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  75%|#######5  | 3/4 [00:02<00:00,  1.21it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|##########| 4/4 [00:03<00:00,  1.51it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|##########| 4/4 [00:03<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "!python ../src/val.py --weights runs/train/LargeDS_cyolo/weights/best.pt --data ../data/All_Volunteers_Crowdsourced.yaml --task test --name LargeDS_cyolo_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4696eaf3-1714-4ef3-98fa-bf8c65819da9",
   "metadata": {},
   "source": [
    "## 1.2  CSexp (Dataset 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b714ba0-c9a3-49c9-bbb4-f7f3e21cc425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e63ed56d-d6f7-4a26-afb3-c7ce47721b6c",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c697e63-3378-4e26-92c9-7d724b732729",
   "metadata": {},
   "source": [
    "{ analysis goes here }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303b45ce-e606-4285-af72-07574fea9976",
   "metadata": {},
   "source": [
    "# Experiment 2 (Crowd RCNN)\n",
    "\n",
    "### This section runs the experiments, prints results, and plots graphs for both dataset using the Crowd RCNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f483542-c475-4af0-839f-fb46f5390657",
   "metadata": {},
   "source": [
    "## 2.1  CSall (Dataset 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c738a97-1f88-4ac8-a31e-f30d1f95d4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661586bb-a974-4827-bbe1-7544554ea747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b418459-5c7a-41fb-ad68-3778917e1c41",
   "metadata": {},
   "source": [
    "## 2.2  CSexp (Dataset 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa25181-ee9b-416b-8196-c11290ce0902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915bc5cf-1862-455f-a261-651e8e0a9599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15e06c44-c3ba-4651-a722-4c73897f10a0",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78670b00-6e68-45b2-9c22-f6bc13dc4de9",
   "metadata": {},
   "source": [
    "{ analysis goes here }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f11d7f3-7d99-4f76-b240-ac3df05555ac",
   "metadata": {},
   "source": [
    "# Experiment 3 (YoloV5 IID)\n",
    "\n",
    "### This section runs the experiments, prints results, and plots graphs for ranomly selected ground truth labels for both dataset using the YoloV5 model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3aab15-d2ea-44a9-92be-90f24cc3b6a9",
   "metadata": {},
   "source": [
    "## 3.1  CSall (Dataset 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f747a954-0d4f-4ed8-9f8d-c2d13d4a5d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdddetection\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=..\\yolov5-master\\yolov5s.pt, cfg=, data=../data/All_Volunteers_IID.yaml, hyp=..\\yolov5-master\\data\\hyps\\hyp.scratch.yaml, epochs=20, batch_size=20, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=..\\yolov5-master\\runs\\train, name=testIIDZOON, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "YOLOv5  2022-2-8 torch 1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 3090, 24576MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ..\\yolov5-master\\runs\\train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/dddetection/train/runs/3ptkpd13\" target=\"_blank\">testIIDZOON</a></strong> to <a href=\"https://wandb.ai/dddetection/train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 270 layers, 7027720 parameters, 7027720 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from ..\\yolov5-master\\yolov5s.pt\n",
      "Scaled weight_decay = 0.00046875\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '..\\data\\datasets\\All_Volunteers_IID\\labels\\train' images and labels...8520 found, 0 missing, 0 empty, 5 corrupted: 100%|██████████| 8520/8520 [00:13<00:00, 618.45it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: ..\\data\\datasets\\All_Volunteers_IID\\images\\train\\Unknown-X-20200130-084742-XLGSYPPPTEXC-0.2fa26163bc112ae3204a.JPG: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0033]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: ..\\data\\datasets\\All_Volunteers_IID\\images\\train\\Unknown-X-20200721-090447-XBKCLNGAJQNH-0.5a634d4f0fcf8ec9e461.JPG: ignoring corrupt image/label: negative label values [   -0.14314    -0.41709]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: ..\\data\\datasets\\All_Volunteers_IID\\images\\train\\Unknown-X-20201005-103909-XNCQOIKATKR9-0.c3c14eb7ba080412ee36.JPG: ignoring corrupt image/label: negative label values [  -0.034393]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: ..\\data\\datasets\\All_Volunteers_IID\\images\\train\\Unknown-X-20201006-084132-XVLTASWWP5TM-0.682d8a57a91ea2f10b4a.JPG: ignoring corrupt image/label: negative label values [    -0.1901    -0.19213]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: ..\\data\\datasets\\All_Volunteers_IID\\images\\train\\Unknown-X-20201030-092621-XJLBBLWGSTK3-0.ff2c4f12241c167761cc.JPG: ignoring corrupt image/label: negative label values [   -0.74383]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Cache directory ..\\data\\datasets\\All_Volunteers_IID\\labels is not writeable: [WinError 183] Cannot create a file when that file already exists: '..\\\\data\\\\datasets\\\\All_Volunteers_IID\\\\labels\\\\train.cache.npy' -> '..\\\\data\\\\datasets\\\\All_Volunteers_IID\\\\labels\\\\train.cache'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\data\\datasets\\All_Volunteers_IID\\labels\\val' images and labels...947 found, 0 missing, 0 empty, 1 corrupted: 100%|██████████| 947/947 [00:06<00:00, 142.79it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING: ..\\data\\datasets\\All_Volunteers_IID\\images\\val\\IX20191022_101649_0368_00003706.1a309d95dd140892a121.JPG: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0002]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING: Cache directory ..\\data\\datasets\\All_Volunteers_IID\\labels is not writeable: [WinError 183] Cannot create a file when that file already exists: '..\\\\data\\\\datasets\\\\All_Volunteers_IID\\\\labels\\\\val.cache.npy' -> '..\\\\data\\\\datasets\\\\All_Volunteers_IID\\\\labels\\\\val.cache'\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.18 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m..\\yolov5-master\\runs\\train\\testIIDZOON2\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module 'signal' has no attribute 'SIGALRM'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/19     4.33G   0.09036   0.04595   0.03228        99       640: 100%|██████████| 426/426 [02:00<00:00,  3.54it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:06<00:00,  3.53it/s]\n",
      "                 all        946       2967     0.0429      0.231     0.0272    0.00621\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/19     5.69G   0.07681   0.04775   0.02225        57       640: 100%|██████████| 426/426 [01:58<00:00,  3.61it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:07<00:00,  3.07it/s]\n",
      "                 all        946       2967       0.11      0.105     0.0384     0.0096\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/19     5.69G   0.07455   0.04713   0.01962        91       640: 100%|██████████| 426/426 [01:58<00:00,  3.60it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:06<00:00,  3.86it/s]\n",
      "                 all        946       2967     0.0981      0.157     0.0507     0.0121\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/19     5.69G   0.07339   0.04789   0.01903        64       640: 100%|██████████| 426/426 [01:57<00:00,  3.62it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:07<00:00,  3.39it/s]\n",
      "                 all        946       2967      0.108      0.151     0.0555     0.0145\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/19     5.69G   0.07213   0.04754   0.01827        58       640: 100%|██████████| 426/426 [01:59<00:00,  3.56it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:05<00:00,  4.14it/s]\n",
      "                 all        946       2967      0.119      0.155     0.0616     0.0159\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/19     5.69G   0.07126   0.04785   0.01763        74       640: 100%|██████████| 426/426 [01:58<00:00,  3.59it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:07<00:00,  3.12it/s]\n",
      "                 all        946       2967      0.134      0.158     0.0672     0.0182\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/19     5.69G   0.07057    0.0475   0.01715        71       640: 100%|██████████| 426/426 [02:03<00:00,  3.44it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:05<00:00,  4.30it/s]\n",
      "                 all        946       2967       0.14      0.151      0.067     0.0178\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/19     5.69G   0.07032   0.04764   0.01729        82       640: 100%|██████████| 426/426 [01:58<00:00,  3.58it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:07<00:00,  3.30it/s]\n",
      "                 all        946       2967      0.131      0.184     0.0719     0.0193\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/19     5.69G   0.06974   0.04779   0.01673        69       640: 100%|██████████| 426/426 [01:59<00:00,  3.56it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:05<00:00,  4.33it/s]\n",
      "                 all        946       2967      0.135      0.159     0.0694     0.0187\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/19     5.69G   0.06946   0.04763    0.0167        74       640: 100%|██████████| 426/426 [02:00<00:00,  3.55it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:07<00:00,  3.38it/s]\n",
      "                 all        946       2967      0.143       0.18     0.0692     0.0181\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/19     5.69G   0.06877   0.04761   0.01649       100       640: 100%|██████████| 426/426 [02:05<00:00,  3.39it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:05<00:00,  4.12it/s]\n",
      "                 all        946       2967       0.14      0.162     0.0713     0.0185\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/19     5.69G   0.06847   0.04734   0.01607        59       640: 100%|██████████| 426/426 [02:02<00:00,  3.49it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:07<00:00,  3.39it/s]\n",
      "                 all        946       2967      0.124      0.166      0.068     0.0177\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/19     5.69G   0.06787   0.04755   0.01588        50       640: 100%|██████████| 426/426 [01:55<00:00,  3.69it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:05<00:00,  4.26it/s]\n",
      "                 all        946       2967      0.143      0.169     0.0708     0.0197\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/19     5.69G    0.0675   0.04774   0.01579        96       640: 100%|██████████| 426/426 [01:57<00:00,  3.63it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:06<00:00,  3.70it/s]\n",
      "                 all        946       2967      0.181      0.153     0.0764     0.0213\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/19     5.69G    0.0673   0.04759   0.01553        61       640: 100%|██████████| 426/426 [01:55<00:00,  3.68it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:05<00:00,  4.29it/s]\n",
      "                 all        946       2967      0.188      0.154     0.0786     0.0212\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/19     5.69G   0.06694   0.04772   0.01521        64       640: 100%|██████████| 426/426 [01:55<00:00,  3.68it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:06<00:00,  3.45it/s]\n",
      "                 all        946       2967      0.164      0.157     0.0787     0.0216\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/19     5.69G   0.06651    0.0478   0.01507        84       640: 100%|██████████| 426/426 [01:55<00:00,  3.70it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:05<00:00,  4.26it/s]\n",
      "                 all        946       2967      0.133       0.19     0.0767     0.0212\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/19     5.69G   0.06592   0.04769   0.01479        94       640: 100%|██████████| 426/426 [01:55<00:00,  3.70it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:06<00:00,  3.53it/s]\n",
      "                 all        946       2967       0.14      0.185     0.0768     0.0212\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/19     5.69G   0.06581   0.04728   0.01473        73       640: 100%|██████████| 426/426 [01:55<00:00,  3.70it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:05<00:00,  4.29it/s]\n",
      "                 all        946       2967      0.138      0.184     0.0788     0.0222\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/19     5.69G   0.06517   0.04799   0.01463        76       640: 100%|██████████| 426/426 [01:55<00:00,  3.70it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:06<00:00,  3.54it/s]\n",
      "                 all        946       2967      0.163      0.171     0.0769     0.0211\n",
      "\n",
      "20 epochs completed in 0.697 hours.\n",
      "\n",
      "Validating ..\\yolov5-master\\runs\\train\\testIIDZOON2\\weights\\best.pt...\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from ..\\yolov5-master\\runs\\train\\testIIDZOON2\\weights\\last.pt, 14.4MB\n",
      "Optimizer stripped from ..\\yolov5-master\\runs\\train\\testIIDZOON2\\weights\\best.pt, 14.4MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|██████████| 24/24 [00:08<00:00,  2.95it/s]\n",
      "                 all        946       2967      0.138      0.184     0.0791     0.0221\n",
      "     calculus-plaque        946        586      0.139      0.142     0.0791     0.0227\n",
      "       dental-caries        946       1239      0.148      0.148     0.0744     0.0225\n",
      "           bone-loss        946       1142      0.127      0.263     0.0838      0.021\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 23836... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 56.09MB of 58.74MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.954926170…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>metrics/mAP_0.5</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇████████</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>▁▂▄▅▅▆▆▇▆▆▆▆▇██████▇█</td></tr><tr><td>metrics/precision</td><td>▁▄▄▄▅▅▆▅▅▆▆▅▆██▇▅▆▆▇▆</td></tr><tr><td>metrics/recall</td><td>█▁▄▄▄▄▄▅▄▅▄▄▅▄▄▄▆▅▅▅▅</td></tr><tr><td>train/box_loss</td><td>█▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train/cls_loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train/obj_loss</td><td>▁▇▅█▆█▆▇▇▇▇▆▆▇▇▇▇▇▆█</td></tr><tr><td>val/box_loss</td><td>█▇▄▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val/cls_loss</td><td>█▅▃▂▂▂▂▂▁▁▁▁▂▁▂▁▁▂▂▂▂</td></tr><tr><td>val/obj_loss</td><td>▁█▄▂▅▃▅▂▃▄▃▄▂▃▃▃▂▃▂▃▂</td></tr><tr><td>x/lr0</td><td>▃▅███▇▇▇▆▆▅▅▄▃▃▂▂▂▁▁</td></tr><tr><td>x/lr1</td><td>▃▅███▇▇▇▆▆▅▅▄▃▃▂▂▂▁▁</td></tr><tr><td>x/lr2</td><td>█▅▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best/epoch</td><td>18</td></tr><tr><td>best/mAP_0.5</td><td>0.07879</td></tr><tr><td>best/mAP_0.5:0.95</td><td>0.02223</td></tr><tr><td>best/precision</td><td>0.1381</td></tr><tr><td>best/recall</td><td>0.18424</td></tr><tr><td>metrics/mAP_0.5</td><td>0.07912</td></tr><tr><td>metrics/mAP_0.5:0.95</td><td>0.02207</td></tr><tr><td>metrics/precision</td><td>0.138</td></tr><tr><td>metrics/recall</td><td>0.18401</td></tr><tr><td>train/box_loss</td><td>0.06517</td></tr><tr><td>train/cls_loss</td><td>0.01463</td></tr><tr><td>train/obj_loss</td><td>0.04799</td></tr><tr><td>val/box_loss</td><td>0.06966</td></tr><tr><td>val/cls_loss</td><td>0.01748</td></tr><tr><td>val/obj_loss</td><td>0.03805</td></tr><tr><td>x/lr0</td><td>0.00122</td></tr><tr><td>x/lr1</td><td>0.00122</td></tr><tr><td>x/lr2</td><td>0.00122</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 335 media file(s), 1 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">testIIDZOON</strong>: <a href=\"https://wandb.ai/dddetection/train/runs/3ptkpd13\" target=\"_blank\">https://wandb.ai/dddetection/train/runs/3ptkpd13</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20220209_164454-3ptkpd13\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1m..\\yolov5-master\\runs\\train\\testIIDZOON2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "%run -i ../src/train.py --data ../data/All_Volunteers_IID.yaml --batch-size 20 --epochs 20 --device 0 --name testIIDZOON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bcbb91-a683-42de-8393-8458d455e011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6805404d-be9c-47d3-bfb1-8fe0c8ba3a13",
   "metadata": {},
   "source": [
    "## 3.2  CSexp (Dataset 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e2c815-5251-4d88-85ec-60ec8b16d5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1ad9ee-b6e7-4a4e-a5e4-a037f4f5e5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8043373-a54a-4eaf-8a2d-96649fe83f6e",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9773f7-612e-449a-9edb-e7bdb5f5c10c",
   "metadata": {},
   "source": [
    "{ analysis goes here }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c10c65-2246-449a-a753-8115207aa3f1",
   "metadata": {},
   "source": [
    "# Experiment 4 (YoloV5 Agregation Preprocessing)\n",
    "\n",
    "### This section runs the experiments, prints results, and plots graphs for both dataset where ground truth labels are agregated into ground truth labels. This experiment also uses YoloV5 as the object detection algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4676442-4671-4e5d-a0f5-318c19f04f4b",
   "metadata": {},
   "source": [
    "## 4.1  CSall (Dataset 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8e4953-f2e8-45b3-a6f5-5d4f59af554e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924cdec6-0eee-4377-ae34-6b7d602b184e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86c244be-7fd6-4a5c-8df0-b74cd05b938e",
   "metadata": {},
   "source": [
    "## 4.2  CSexp (Dataset 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb5396a-7972-4cf9-a20b-607d09fd69da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd1931c-4fe2-4c11-b5ee-f31d94d93085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2869902-e5fe-4849-815b-d881bdaef5dd",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6265babd-7dac-49f1-9953-8d55e276777a",
   "metadata": {},
   "source": [
    "{ analysis goes here }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98a9c43-9af8-433e-9e07-56be9e76c5ae",
   "metadata": {},
   "source": [
    "# Conclusion Experiment Set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da0712c-6551-4721-a6a6-fb9a10b9fe35",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
